"""
Scan clustering n and saves plots dendograms, cluster seqs and assemblies for all of them
last modified: Andr√°s Ecker 01.2023
"""

import os
import warnings
import numpy as np
from scipy.spatial.distance import pdist, cdist, squareform
from scipy.optimize import linear_sum_assignment
from scipy.cluster.hierarchy import linkage, fcluster

from assemblyfire.config import Config
import assemblyfire.utils as utils
from assemblyfire.clustering import cosine_similarity, detect_assemblies
from assemblyfire.plots import plot_dendogram_silhouettes, plot_cluster_seqs, plot_distance_corr


def get_pattern_distance(locf_name, pklf_name):
    """Gets Earth mover's distance of the input pattern fibers"""
    tmp = np.loadtxt(locf_name)
    gids, pos = tmp[:, 0].astype(int), tmp[:, 1:]
    pattern_gids = utils.get_pattern_gids(pklf_name)
    pattern_pos = {pattern_name: pos[np.in1d(gids, gids_, assume_unique=True), :]
                   for pattern_name, gids_ in pattern_gids.items()}
    pattern_names = np.sort(list(pattern_pos.keys()))
    row_idx, col_idx = np.triu_indices(len(pattern_names), k=1)
    emd = np.zeros_like(row_idx, dtype=np.float32)
    for i, (row_id, col_id) in enumerate(zip(row_idx, col_idx)):
        dists = cdist(pattern_pos[pattern_names[row_id]], pattern_pos[pattern_names[col_id]])
        emd[i] = np.sum(dists[linear_sum_assignment(dists)]) / len(pattern_pos[pattern_names[row_id]])
    return pattern_names, emd


def get_assembly_count_distance(clusters, t_bins, stim_times, patterns, distance_metric="normalized_euclidean"):
    """Gets distance of the assembly counts"""
    _, _, _, pattern_counts = utils.group_clusters_by_patterns(clusters, t_bins, stim_times, patterns)
    # reorder dict to a matrix form
    pattern_names = np.sort(list(pattern_counts.keys()))
    matrix = np.vstack([pattern_counts[pattern_name] for pattern_name in pattern_names])
    if distance_metric == "emd":
        from scipy.stats import wasserstein_distance
        row_idx, col_idx = np.triu_indices(len(pattern_names), 1)
        emd = np.array([wasserstein_distance(matrix[row_id, :], matrix[col_id, :])
                        for row_id, col_id in zip(row_idx, col_idx)])
        return pattern_names, emd
    elif distance_metric == "normalized_euclidean":
        row_idx, col_idx = np.triu_indices(len(pattern_names), 1)
        dists = np.zeros_like(row_idx, dtype=np.float32)
        for i, (row_id, col_id) in enumerate(zip(row_idx, col_idx)):
            a, b = matrix[row_id] - np.mean(matrix[row_id]), matrix[col_id] - np.mean(matrix[col_id])
            dists[i] = np.sqrt(0.5 * np.linalg.norm(a - b) ** 2 / (np.linalg.norm(a) ** 2 + np.linalg.norm(b) ** 2))
        return pattern_names, dists
    else:
        return pattern_names, pdist(matrix, distance_metric)


def cluster_sim_mat(spike_matrix, t_bins, stim_times, patterns, input_pattern_names, input_dist, fig_dir,
                    min_n_clusts=5, max_n_clusts=20):
    """Modified version of `assemblyfire.clustering/cluster_sim_mat()` that plot results for all `n_clusts`"""
    sim_matrix = cosine_similarity(spike_matrix.T)
    dists = 1 - sim_matrix
    dists[dists < 1e-10] = 0.  # fixing numerical errors
    cond_dists = squareform(dists)  # squareform implements its inverse if the input is a square matrix
    linkage_matrix = linkage(cond_dists, method="ward")

    # iterate over number of clusters and plot results for all
    n_clusters = {}
    for n in range(min_n_clusts, max_n_clusts+1):
        clusters = fcluster(linkage_matrix, n, criterion="maxclust")
        n_clusters[n] = clusters
        output_pattern_names, output_dist = get_assembly_count_distance(clusters, t_bins, stim_times, patterns)

        plot_dendogram_silhouettes(clusters, linkage_matrix, None, os.path.join(fig_dir, "ward_clustering_n%i.png" % n))
        plot_cluster_seqs(clusters, t_bins, stim_times, patterns, os.path.join(fig_dir, "cluster_seq_n%i.png" % n))
        if (input_pattern_names != output_pattern_names).all():
            warnings.warn("Input and output pattern names don't match!")
        else:
            plot_distance_corr(input_dist, output_dist, os.path.join(fig_dir, "input_vs_output_dists_n%i.png" % n))

    return n_clusters


def main(config_path, seeds, save_assemblies=True):
    config = Config(config_path)
    spike_matrix_dict, project_metadata = utils.load_spikes_from_h5(config.h5f_name)
    stim_times, patterns = project_metadata["stim_times"], project_metadata["patterns"]
    input_pattern_names, input_dist = get_pattern_distance(config.pattern_locs_fname, config.pattern_gids_fname)
    nrn_loc_df = utils.get_neuron_locs(utils.get_sim_path(config.root_path).iloc[0], config.target)

    for seed in seeds:
        spike_matrix, t_bins = spike_matrix_dict["seed%i" % seed].spike_matrix, spike_matrix_dict["seed%i" % seed].t_bins
        fig_dir = os.path.join(config.fig_path, "seed%i_debug" % seed)
        utils.ensure_dir(fig_dir)
        n_clusters = cluster_sim_mat(spike_matrix, t_bins, stim_times, patterns, input_pattern_names, input_dist, fig_dir)
        if save_assemblies:
            # create "fake" dictionary of spike matrices for different ns,
            # so the looping (and proper saving) will be done by `detect_assemblies`
            n_spike_matrix = {n: spike_matrix_dict["seed%i" % seed] for n, _ in n_clusters.items()}
            h5f_name = config.h5f_name.split(".h5")[0] + "_across_ns.h5"
            detect_assemblies(n_spike_matrix, n_clusters, config.core_cell_th_pct, h5f_name,
                              config.h5_prefix_assemblies, nrn_loc_df, fig_dir)


if __name__ == "__main__":
    config_path = "/gpfs/bbp.cscs.ch/project/proj96/home/ecker/assemblyfire/configs/v7_10seeds_np.yaml"
    seeds = [19]
    main(config_path, seeds)

